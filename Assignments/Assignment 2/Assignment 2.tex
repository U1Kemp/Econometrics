\documentclass[a4paper]{article}
\usepackage[a4paper, top=1in, left=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{booktabs} % For table resizing

\pagestyle{fancy}
\fancyhf{}
\rhead{Econometrics Homework 2}
\lhead{Utpalraj Kemprai}

\cfoot{\thepage}

\begin{document}

\title{Econometrics Homework 2}
\author{Utpalraj Kemprai \\
MDS202352}
\date{\today}

\maketitle

\newpage

\section*{Question 1}

We have the following ordinal regression model:
\begin{align*}
    z_{i} &= x'_{i}\beta + \epsilon_{i} \quad \forall i = 1,\cdots,n \\
    \gamma_{j-1} &< z_{i} \leq \gamma_{j} \implies y_{i} = j, \quad \forall i, j = 1, \cdots, J
\end{align*}
where (in the first equation) $z_i$ is the latent variable for individual $i$, $x_i$ is a  vector of covariates,
$\beta$ is a $k\times1$ vector of unknown parameters, and $n$ denotes the number of observations. The second equation shows how $z_i$ is related to the observed discrete response $y_i$, where $-\infty = \gamma_0 < \gamma_1 <
\gamma_{J-1} < \gamma_J = \infty$ are the cut-points (or thresholds) and $y_i$ is assumed to have $J$ categories or outcomes.

\subsection*{(a)}

\subsubsection*{Probability of success}

We assume that $\epsilon_i \sim N(0,1)$, for $i = 1,2,\cdots, n$. Therefore we have,\\
The probability of success,
\begin{align*}
    Pr(y_i = j) &= Pr(\gamma_{j-1} < z_{i} \leq \gamma_j)\\
                &= Pr(\gamma_{j-1} < x'_{i}\beta + \epsilon_{i} \leq \gamma_j) \\
                &= Pr(\gamma_{j-1} - x'_{i}\beta < \epsilon_{i} \leq \gamma_j - x'_{i}\beta)\\
                &= \Phi(\gamma_j - x'_{i}\beta) - \Phi(\gamma_{j-1} - x'_{i}\beta) &[\text{where } \Phi(\cdot) \text{ is the cdf of }N(0,1) ]
\end{align*}

\subsubsection*{Likelihood function}

The likelihood function for the ordinal probit model is,
\begin{align*}
    L(\beta,\gamma;y) &= \prod_{i=1}^{n}\prod_{j=1}^{J} Pr(y_i = j | \beta,\gamma)^{I(y_i = j)} &[\text{where } I(\cdot) \text{ is the indicator function}]\\
                      &= \prod_{i=1}^{n}\prod_{j=1}^{J} (\Phi(\gamma_j - x'_{i}\beta) - \Phi(\gamma_{j-1} - x'_{i}\beta))^{I(y_i = j)}
\end{align*}

\subsection*{(b)}

\subsubsection*{Probability of success}

We assume that $\epsilon_i \sim \mathcal{L}(0,1)$, for $i = 1,2, \cdots, n$. Therefore the probability of success,
\begin{align*}
    Pr(y_i = j) &= Pr(\gamma_{j-1} < z_{i} \leq \gamma_j)\\
                &= Pr(\gamma_{j-1} < x'_{i}\beta + \epsilon_{i} \leq \gamma_j) \\
                &= Pr(\gamma_{j-1} - x'_{i}\beta < \epsilon_{i} \leq \gamma_j - x'_{i}\beta) \\
                &= \frac{1}{1+e^{-(\gamma_j - x'_{i}\beta)}} - \frac{1}{1+e^{-(\gamma_{j-1} - x'_{i}\beta)}} & [\text{as } \epsilon_i \sim \mathcal{L}(0,1)] \\
                &= \frac{e^{-(\gamma_{j-1} - x'_{i}\beta)} - e^{-(\gamma_{j} - x'_{i}\beta)}}{(1+e^{-(\gamma_j - x'_{i}\beta)})(1+e^{-(\gamma_{j-1} - x'_{i}\beta)})} \\
                &= \frac{e^{x'_i\beta}(e^{-\gamma_{j-1}} - e^{-\gamma_{j}})}{(1+e^{-(\gamma_j - x'_{i}\beta)})(1+e^{-(\gamma_{j-1} - x'_{i}\beta)})} 
\end{align*}

\subsubsection*{Likelihood function}

The likelihood function for the ordinal logit model is,
\begin{align*}
    L(\beta,\gamma;y) &= \prod_{i=1}^{n}\prod_{j=1}^{J} Pr(y_i = j | \beta, \gamma)^{I(y_i = j)} &[\text{where } I(\cdot) \text{ is the indicator function}]\\
                      &=\prod_{i=1}^{n}\prod_{j=1}^{J} [\frac{e^{x'_i\beta}(e^{-\gamma_{j-1}} - e^{-\gamma_{j}})}{(1+e^{-(\gamma_j - x'_{i}\beta)})(1+e^{-(\gamma_{j-1} - x'_{i}\beta)})}]^{I(y_i = j)} 
\end{align*}

\subsection*{(c)}

\subsubsection*{Probability remain unchanged on adding a constant c to cut-points and the mean}

Adding a constant $c$ to the cut-point $\gamma_j$ and the mean $x'_i\beta$, $\forall i = 1,2, \cdots, n$ and $j = 1,2,\cdots, J$, the latent variable $z_i$ becomes $x'_i\beta + c + \epsilon_i$ and the cut-point $\gamma_j$ becomes $\gamma_j + c$

The probability of $y_i$ taking the value $j$ is,
\begin{align*}
    Pr(y_i = j) &= Pr(\gamma_{j-1}+c < z_i \leq \gamma_j + c)\\
                &= Pr(\gamma_{j-1}+c < x'_i\beta + c + \epsilon_i \leq \gamma_j + c)\\
                &= Pr(\gamma_{j-1} - x'_i\beta  < \epsilon_i \leq \gamma_j - x'_i\beta ) \\
                &= \Phi(\gamma_j - x'_i\beta) - \Phi(\gamma_{j-1} - x'_i\beta)
\end{align*}
which is the same as the value obtained in part(a) of Question 1. So adding a constant c to the cut-point $\gamma_j$ and the mean $x'_i\beta$ does not change the outcome probability.

\subsubsection*{Identification Problem}
This identification problem can be solved by fixing the value of one of $\gamma_1, \gamma_2, \cdots, \gamma_{J-1}$. In particular setting $\gamma_1 = 0$ will solve this identification problem.

\subsection*{(d)}

\subsubsection*{Rescaling the parameters $(\gamma_j,\beta)$ and scale of distribution does not change outcome probability}

Rescaling the parameters $(\gamma_j,\beta)$ and the scale of the distribution of $\epsilon_i$ by some constant $d$, the latent variable $z_i$ becomes $x'_id\beta + \epsilon_i$ where $\epsilon_i \sim N(0,d^2)$ and the cut-point $\gamma_j$ becomes $d\gamma_j, \forall j = 1, 2, \cdots, J-1$.

The probability of $y_i$ taking the value $j$ is,
\begin{align*}
    Pr(y_i=j) &= Pr(d\gamma_{j-1} < z_i \leq d\gamma_j) \\
              &= Pr(d\gamma_{j-1} < x'_i d\beta + \epsilon_i \leq d\gamma_j)\\
              &= Pr(\gamma_{j-1} - x'_i\beta < \frac{\epsilon_i}{d} \leq \gamma_j - x'_i\beta)\\
              &= \Phi(\gamma_j - x'_i\beta) - \Phi(\gamma_{j-1} - x'_i\beta) & [\text{as } \epsilon_i \sim N(0,d^2), \frac{\epsilon_i}{d} \sim N(0,1)]
\end{align*}
which is the same as the value obtained in part(b) of Question 1. So escaling the parameters $(\gamma_j,\beta)$ and the scale of the distribution by some arbitrary constant $d$ lead to same outcome probabilities.

\subsubsection*{Identification problem}
This identification problem can be solved by fixing the scale of the distribution of $\epsilon_i$. In particular we can set the scale of the distribution of $\epsilon_i$ to 1, i.e. var($\epsilon_i$) = 1.

\subsection*{(e)}

\subsubsection*{(i) Descriptive Summary of the data}


\subsubsection*{(ii) Public opinion on extent of marijuana legalization}


\subsubsection*{(iii) Covariate effects of the variables}


\newpage
\section*{Question 2}
\end{document}